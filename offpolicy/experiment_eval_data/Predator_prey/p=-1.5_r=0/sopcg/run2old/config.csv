Name,Value
algorithm_name,sopcg
experiment_name,p=-1.5_r=0
seed,88
cuda,False
cuda_deterministic,True
n_training_threads,2
n_rollout_threads,1
n_eval_rollout_threads,1
num_env_steps,2000000
use_wandb,False
user_name,shiyuchen
env_name,Predator_prey
use_obs_instead_of_state,False
episode_length,200
buffer_size,5000
adj_buffer_size,32
use_reward_normalization,True
use_popart,False
popart_update_interval_step,2
use_per,False
per_nu,0.9
per_alpha,0.6
per_eps,1e-06
per_beta_start,0.4
use_centralized_Q,True
share_policy,True
hidden_size,64
layer_N,1
use_ReLU,True
use_feature_normalization,True
use_orthogonal,True
gain,0.01
use_conv1d,False
stacked_frames,1
use_cell,False
prev_act_inp,False
use_rnn_layer,True
use_naive_recurrent_policy,True
recurrent_N,1
data_chunk_length,80
burn_in_time,0
attn,False
attn_N,1
attn_size,64
attn_heads,4
dropout,0.0
use_average_pool,True
use_cat_self,True
adj_lr,0.05
lr,0.001
opti_eps,1e-05
opti_alpha,0.99
weight_decay,0
batch_size,8
gamma,0.97
gae_lambda,0.95
use_max_grad_norm,True
max_grad_norm,10
use_huber_loss,False
huber_delta,10.0
use_soft_update,False
tau,0.005
hard_update_interval_episode,200
hard_update_interval,200
target_action_noise_std,0.2
alpha,0.1
target_entropy_coef,0.5
automatic_entropy_tune,True
use_double_q,True
hypernet_layers,2
mixer_hidden_dim,32
hypernet_hidden_dim,64
w,0.1
central_action_embed,1
central_mixing_embed_dim,256
hysteretic_qmix,False
qtran_hidden_dim,64
lambda_opt,1
lambda_nopt,1.0
n_head,4
num_kernel,10
adv_hypernet_embed,64
weighted_head,True
is_minus_one,True
adv_hypernet_layers,3
attend_reg_coef,0.001
state_bias,True
mask_dead,False
nonlinear,False
use_dyn_graph,False
num_rank,3
equal_vdn,False
msg_anytime,True
msg_normalized,True
lamda,0.0
msg_iterations,4
adj_hidden_dim,32
adj_output_dim,2
adj_alpha,0.1
clip_param,0.2
adj_lambda,1
use_linear_lr_decay,False
entropy_coef,0.001
use_valuenorm,False
use_vfunction,False
use_epsilon_greedy,False
individual_q,True
construction,tree
num_random_episodes,5
epsilon_start,1.0
epsilon_finish,0.05
epsilon_anneal_time,50000
adj_anneal_time,800000
disount_step,500000
act_noise_std,0.1
actor_train_interval_step,2
train_interval_episode,1
train_adj_episode,4
drop_temperature_episode,10
train_interval,100
use_value_active_masks,False
use_eval,True
eval_interval,2000
num_eval_episodes,10
save_interval,100000
use_save,True
log_interval,1000
model_dir,
use_available_actions,True
use_same_share_obs,True
use_global_all_local_state,False
num_stags,6
num_hare,0
num_agents,9
toroidal,False
world_shape,"[10, 10]"
agent_obs,"[2, 2]"
agent_move_block,"[0, 1, 2]"
capture_action_conditions,"[3, 1]"
reward_hare,1
reward_stag,10
reward_collision,0
reward_time,0.0
miscapture_punishment,-1.5
capture_action,True
capture_terminal,False
p_stags_rest,0
p_hare_rest,0
prevent_cannibalism,True
remove_frozen,True
capture_freezes,False
num_factor,45
highest_orders,3
